{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Sistema Sussy - Entrenamiento Unificado (Colab / Lambda / Local)\n",
        "\n",
        "Este notebook permite entrenar modelos de detecci√≥n jer√°rquica en **m√∫ltiples plataformas**:\n",
        "\n",
        "| Plataforma | GPU | Uso recomendado |\n",
        "|------------|-----|-----------------|\n",
        "| **Google Colab** | T4/L4 gratis | Pruebas r√°pidas, entrenamiento peque√±o |\n",
        "| **Lambda Labs** | A10/A100 | Entrenamiento serio, datasets grandes |\n",
        "| **Local CPU** | - | Verificar pipeline, pruebas m√≠nimas |\n",
        "\n",
        "## üìã Pasos:\n",
        "1. Conectar GPU (Colab: Runtime > T4/L4 | Lambda: ya incluida)\n",
        "2. Preparar dataset (extraer frames + anotar)\n",
        "3. Configurar el entrenamiento (auto-detecta hardware)\n",
        "4. Entrenar y exportar modelo ONNX\n",
        "\n",
        "**IMPORTANTE:** Ejecuta las celdas en orden. El sistema detecta autom√°ticamente el entorno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1Ô∏è‚É£ Detectar Entorno y Configurar\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# Detectar plataforma\n",
        "def detectar_plataforma():\n",
        "    if os.environ.get(\"COLAB_GPU\") or \"google.colab\" in str(globals()):\n",
        "        return \"COLAB\"\n",
        "    elif os.environ.get(\"LAMBDA_TASK_ROOT\") or \"lambda\" in platform.node().lower():\n",
        "        return \"LAMBDA\"\n",
        "    elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
        "        return \"KAGGLE\"\n",
        "    else:\n",
        "        return \"LOCAL\"\n",
        "\n",
        "PLATAFORMA = detectar_plataforma()\n",
        "print(f\"üñ•Ô∏è Plataforma detectada: {PLATAFORMA}\")\n",
        "\n",
        "# Verificar GPU\n",
        "try:\n",
        "    result = os.popen('nvidia-smi --query-gpu=name,memory.total --format=csv,noheader').read()\n",
        "    if result.strip():\n",
        "        print(f\"\\nüéÆ GPU(s) detectadas:\")\n",
        "        for line in result.strip().split('\\n'):\n",
        "            print(f\"   {line}\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è No se detect√≥ nvidia-smi\")\n",
        "\n",
        "import torch\n",
        "print(f\"\\nüì¶ PyTorch version: {torch.__version__}\")\n",
        "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Test real de CUDA\n",
        "CUDA_FUNCIONAL = False\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        test = torch.zeros(1, device=\"cuda\")\n",
        "        del test\n",
        "        CUDA_FUNCIONAL = True\n",
        "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"‚úÖ CUDA funcional: ¬°S√≠!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è GPU detectada pero CUDA no funcional: {e}\")\n",
        "        print(\"   Usaremos CPU para entrenamiento\")\n",
        "\n",
        "DEVICE = \"cuda\" if CUDA_FUNCIONAL else \"cpu\"\n",
        "print(f\"\\nüéØ Device a usar: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar Ultralytics (YOLO)\n",
        "!pip install -q ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "print(f\"\\n‚úÖ Ultralytics instalado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2Ô∏è‚É£ Configurar Almacenamiento (adapta a plataforma)\n",
        "import os\n",
        "\n",
        "if PLATAFORMA == \"COLAB\":\n",
        "    # Google Drive para persistencia\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        WORK_DIR = \"/content/drive/MyDrive/Sussy_Training\"\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è No se pudo montar Drive, usando almacenamiento local\")\n",
        "        WORK_DIR = \"/content/sussy_training\"\n",
        "        \n",
        "elif PLATAFORMA == \"LAMBDA\":\n",
        "    # Lambda: usar almacenamiento local (persiste entre sesiones si usas /home)\n",
        "    WORK_DIR = os.path.expanduser(\"~/sussy_training\")\n",
        "    \n",
        "elif PLATAFORMA == \"KAGGLE\":\n",
        "    WORK_DIR = \"/kaggle/working/sussy_training\"\n",
        "    \n",
        "else:  # LOCAL\n",
        "    # Detectar si estamos en el proyecto Sussy\n",
        "    if os.path.exists(\"sussy\"):\n",
        "        WORK_DIR = \"./training_output\"\n",
        "    else:\n",
        "        WORK_DIR = os.path.expanduser(\"~/sussy_training\")\n",
        "\n",
        "# Crear estructura de carpetas\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{WORK_DIR}/datasets\", exist_ok=True)\n",
        "os.makedirs(f\"{WORK_DIR}/models\", exist_ok=True)\n",
        "os.makedirs(f\"{WORK_DIR}/frames\", exist_ok=True)  # Para frames extra√≠dos\n",
        "\n",
        "print(f\"\\nüìÅ Carpeta de trabajo: {WORK_DIR}\")\n",
        "print(f\"   üìÇ datasets/  - Tus datasets anotados\")\n",
        "print(f\"   üìÇ models/    - Modelos entrenados\")\n",
        "print(f\"   üìÇ frames/    - Frames extra√≠dos de v√≠deos\")\n",
        "\n",
        "# Mostrar espacio disponible\n",
        "try:\n",
        "    import shutil\n",
        "    total, used, free = shutil.disk_usage(WORK_DIR)\n",
        "    print(f\"\\nüíæ Espacio disponible: {free // (2**30)} GB\")\n",
        "except:\n",
        "    pass  # No cr√≠tico si falla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé¨ Extracci√≥n de Frames desde V√≠deos\n",
        "\n",
        "**¬øHay que recortar los objetos?**\n",
        "\n",
        "| Fase | Formato de imagen | ¬øRecortar? |\n",
        "|------|-------------------|------------|\n",
        "| **Fase 1: Detecci√≥n** | Imagen COMPLETA + bounding box | ‚ùå No |\n",
        "| **Fases 2-3: Clasificaci√≥n** | CROP del objeto | ‚úÖ S√≠ |\n",
        "| **Fase 4: Atributos** | CROP del objeto | ‚úÖ S√≠ |\n",
        "\n",
        "**¬øFrames similares o variados?**\n",
        "- ‚úÖ Saltar 5-10 frames entre capturas (evita redundancia)\n",
        "- ‚úÖ Incluir diferentes √°ngulos, iluminaci√≥n, fondos\n",
        "- ‚úÖ Incluir oclusiones parciales\n",
        "- ‚ùå Evitar 100 frames id√©nticos del mismo objeto\n",
        "- üí° **Ratio ideal:** ~30% similares + ~70% variados\n",
        "\n",
        "**¬øC√≥mo entrenar atributos (ej: insignia militar)?**\n",
        "```\n",
        "Imagen ‚Üí Detector Persona ‚Üí Crop Persona ‚Üí Clasificador Atributos\n",
        "                                              ‚îú‚îÄ‚îÄ rol: militar\n",
        "                                              ‚îú‚îÄ‚îÄ rango: cabo (detectado por insignia)\n",
        "                                              ‚îî‚îÄ‚îÄ equipamiento: casco, chaleco...\n",
        "```\n",
        "Entrena con la **persona completa** que lleva la insignia. El modelo aprende a buscar la zona relevante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé¨ EXTRAER FRAMES DE V√çDEO (opcional)\n",
        "# ======================================\n",
        "# Sube un v√≠deo y extrae frames inteligentemente\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def extraer_frames_video(\n",
        "    path_video: str,\n",
        "    path_salida: str,\n",
        "    skip_frames: int = 10,      # Extraer 1 de cada N frames\n",
        "    min_blur: float = 100.0,    # Filtrar frames borrosos\n",
        "    max_frames: int = None,     # L√≠mite m√°ximo (None = todos)\n",
        "):\n",
        "    \"\"\"Extrae frames de un v√≠deo con filtrado de calidad.\"\"\"\n",
        "    \n",
        "    path_salida = Path(path_salida)\n",
        "    path_salida.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    cap = cv2.VideoCapture(path_video)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    print(f\"üìπ V√≠deo: {Path(path_video).name}\")\n",
        "    print(f\"   {total} frames, {fps:.1f} FPS, {total/fps:.1f} segundos\")\n",
        "    \n",
        "    frame_idx = 0\n",
        "    saved = 0\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        frame_idx += 1\n",
        "        \n",
        "        # Saltar frames\n",
        "        if frame_idx % skip_frames != 0:\n",
        "            continue\n",
        "        \n",
        "        # Filtrar borrosos (varianza del Laplaciano)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        \n",
        "        if blur_score < min_blur:\n",
        "            continue\n",
        "        \n",
        "        # Guardar\n",
        "        timestamp = frame_idx / fps\n",
        "        nombre = f\"frame_{frame_idx:06d}_t{timestamp:.2f}s.jpg\"\n",
        "        cv2.imwrite(str(path_salida / nombre), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "        saved += 1\n",
        "        \n",
        "        if max_frames and saved >= max_frames:\n",
        "            break\n",
        "    \n",
        "    cap.release()\n",
        "    print(f\"‚úÖ Extra√≠dos {saved} frames en: {path_salida}\")\n",
        "    return saved\n",
        "\n",
        "# =====================================\n",
        "# EJEMPLO DE USO:\n",
        "# =====================================\n",
        "# 1. Sube tu v√≠deo a Colab/Lambda\n",
        "# 2. Descomenta y ejecuta:\n",
        "\n",
        "# extraer_frames_video(\n",
        "#     \"/content/mi_video.mp4\",           # Ruta al v√≠deo\n",
        "#     f\"{WORK_DIR}/frames/mi_video/\",    # Carpeta de salida\n",
        "#     skip_frames=10,                    # 1 de cada 10 frames\n",
        "#     min_blur=100.0,                    # Filtrar borrosos\n",
        "#     max_frames=500,                    # M√°ximo 500 frames\n",
        "# )\n",
        "\n",
        "print(\"üí° Descomenta el c√≥digo de arriba para extraer frames de tu v√≠deo\")\n",
        "print(\"   O sube v√≠deos a la carpeta y ejecuta en batch:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Preparar Dataset\n",
        "\n",
        "**Estructura para Detecci√≥n (imagen completa + anotaciones):**\n",
        "```\n",
        "datasets/mi_dataset/\n",
        "‚îú‚îÄ‚îÄ data.yaml           # Configuraci√≥n (clases, rutas)\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ images/         # Im√°genes completas\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ labels/         # Archivos .txt con bounding boxes\n",
        "‚îî‚îÄ‚îÄ val/\n",
        "    ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îî‚îÄ‚îÄ labels/\n",
        "```\n",
        "\n",
        "**Estructura para Clasificaci√≥n (crops organizados por clase):**\n",
        "```\n",
        "datasets/mi_clasificador/\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ clase1/         # Carpeta por clase\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ clase2/\n",
        "‚îî‚îÄ‚îÄ val/\n",
        "    ‚îú‚îÄ‚îÄ clase1/\n",
        "    ‚îî‚îÄ‚îÄ clase2/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descargar dataset de ejemplo para probar (COCO128)\n",
        "print(\"üì• Descargando dataset de ejemplo...\")\n",
        "!wget -q https://ultralytics.com/assets/coco128.zip -O /content/coco128.zip\n",
        "!unzip -q /content/coco128.zip -d /content/\n",
        "\n",
        "print(\"‚úÖ Dataset COCO128 listo en /content/coco128/\")\n",
        "print(\"   (128 im√°genes con 80 clases - perfecto para probar)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4Ô∏è‚É£ CONFIGURACI√ìN DEL ENTRENAMIENTO\n",
        "# =====================================\n",
        "# El sistema ajusta autom√°ticamente seg√∫n tu hardware\n",
        "\n",
        "# ============ CONFIGURA ESTO ============\n",
        "TIPO = \"detect\"  # \"detect\" o \"classify\"\n",
        "DATASET = \"coco128.yaml\"  # Tu dataset: f\"{WORK_DIR}/datasets/tu_dataset/data.yaml\"\n",
        "PROYECTO = \"sussy_prueba_v1\"\n",
        "\n",
        "# Preset: \"prueba\" (r√°pido), \"desarrollo\" (balance), \"produccion\" (serio)\n",
        "PRESET = \"prueba\" if PLATAFORMA == \"LOCAL\" or not CUDA_FUNCIONAL else \"desarrollo\"\n",
        "# =========================================\n",
        "\n",
        "# Configuraci√≥n autom√°tica seg√∫n preset y hardware\n",
        "PRESETS = {\n",
        "    \"prueba\": {\n",
        "        \"epochs\": 10, \"batch_size\": 4, \"img_size\": 320,\n",
        "        \"patience\": 5, \"modelo\": \"yolo11n.pt\"\n",
        "    },\n",
        "    \"desarrollo\": {\n",
        "        \"epochs\": 50, \"batch_size\": 16, \"img_size\": 640,\n",
        "        \"patience\": 15, \"modelo\": \"yolo11s.pt\"\n",
        "    },\n",
        "    \"produccion\": {\n",
        "        \"epochs\": 100, \"batch_size\": 32, \"img_size\": 640,\n",
        "        \"patience\": 20, \"modelo\": \"yolo11m.pt\"\n",
        "    },\n",
        "    \"lambda_full\": {\n",
        "        \"epochs\": 200, \"batch_size\": 32, \"img_size\": 960,\n",
        "        \"patience\": 30, \"modelo\": \"yolo11l.pt\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Usar Lambda_full si estamos en Lambda\n",
        "if PLATAFORMA == \"LAMBDA\":\n",
        "    PRESET = \"lambda_full\"\n",
        "\n",
        "config = PRESETS[PRESET]\n",
        "EPOCHS = config[\"epochs\"]\n",
        "BATCH_SIZE = config[\"batch_size\"]\n",
        "IMG_SIZE = config[\"img_size\"]\n",
        "PATIENCE = config[\"patience\"]\n",
        "MODELO_BASE = config[\"modelo\"]\n",
        "LEARNING_RATE = 0.01\n",
        "AUGMENT = True\n",
        "\n",
        "# Ajuste de batch si hay poca memoria GPU (< 8GB)\n",
        "if CUDA_FUNCIONAL:\n",
        "    try:\n",
        "        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        if gpu_mem < 8:\n",
        "            BATCH_SIZE = min(BATCH_SIZE, 8)\n",
        "            print(f\"‚ö†Ô∏è GPU con {gpu_mem:.1f}GB: batch reducido a {BATCH_SIZE}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(f\"\\nüìã Configuraci√≥n ({PRESET.upper()}):\")\n",
        "print(f\"   üéØ Tipo: {TIPO}\")\n",
        "print(f\"   üìÇ Dataset: {DATASET}\")\n",
        "print(f\"   ü§ñ Modelo: {MODELO_BASE}\")\n",
        "print(f\"   üî¢ Epochs: {EPOCHS}\")\n",
        "print(f\"   üì¶ Batch: {BATCH_SIZE}\")\n",
        "print(f\"   üñºÔ∏è ImgSize: {IMG_SIZE}\")\n",
        "print(f\"   ‚è±Ô∏è Patience: {PATIENCE}\")\n",
        "print(f\"   üîß Device: {DEVICE}\")\n",
        "print(f\"\\nüí° Modifica PRESET arriba para cambiar la intensidad del entrenamiento\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5Ô∏è‚É£ ENTRENAR MODELO\n",
        "# =====================\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "print(f\"üîÑ Cargando modelo base: {MODELO_BASE}\")\n",
        "model = YOLO(MODELO_BASE)\n",
        "\n",
        "# Determinar device\n",
        "train_device = 0 if DEVICE == \"cuda\" else \"cpu\"\n",
        "print(f\"\\nüöÄ Iniciando entrenamiento en: {DEVICE.upper()}\")\n",
        "print(f\"   Epochs: {EPOCHS}, Batch: {BATCH_SIZE}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=DATASET,\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMG_SIZE,\n",
        "        batch=BATCH_SIZE,\n",
        "        lr0=LEARNING_RATE,\n",
        "        patience=PATIENCE,\n",
        "        augment=AUGMENT,\n",
        "        project=f\"{WORK_DIR}/models\",\n",
        "        name=PROYECTO,\n",
        "        exist_ok=True,\n",
        "        device=train_device,\n",
        "        verbose=True,\n",
        "        half=DEVICE == \"cuda\",  # FP16 solo en GPU\n",
        "        workers=4 if DEVICE == \"cuda\" else 2,\n",
        "    )\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"‚úÖ ¬°Entrenamiento completado en {elapsed/60:.1f} minutos!\")\n",
        "    print(f\"   Modelo guardado en: {WORK_DIR}/models/{PROYECTO}/\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error durante entrenamiento: {e}\")\n",
        "    print(\"\\nüí° Posibles soluciones:\")\n",
        "    print(\"   - Reducir BATCH_SIZE\")\n",
        "    print(\"   - Usar PRESET = 'prueba'\")\n",
        "    print(\"   - Verificar que el dataset existe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6Ô∏è‚É£ VER RESULTADOS DE ENTRENAMIENTO\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "results_dir = f\"{WORK_DIR}/models/{PROYECTO}\"\n",
        "\n",
        "# Mostrar curvas de entrenamiento\n",
        "results_png = os.path.join(results_dir, \"results.png\")\n",
        "if os.path.exists(results_png):\n",
        "    print(\"üìä Curvas de entrenamiento:\")\n",
        "    display(Image(filename=results_png, width=900))\n",
        "\n",
        "# Mostrar matriz de confusi√≥n (si existe)\n",
        "confusion_png = os.path.join(results_dir, \"confusion_matrix.png\")\n",
        "if os.path.exists(confusion_png):\n",
        "    print(\"\\nüìä Matriz de confusi√≥n:\")\n",
        "    display(Image(filename=confusion_png, width=700))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7Ô∏è‚É£ EXPORTAR A ONNX (para tu RTX 5080)\n",
        "# =========================================\n",
        "best_model_path = f\"{WORK_DIR}/models/{PROYECTO}/weights/best.pt\"\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(\"üì¶ Exportando modelo a ONNX...\")\n",
        "    \n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Exportar a ONNX\n",
        "    onnx_path = model.export(format=\"onnx\", imgsz=IMG_SIZE, simplify=True)\n",
        "    \n",
        "    # Tama√±os de archivo\n",
        "    pt_size = os.path.getsize(best_model_path) / 1024 / 1024\n",
        "    onnx_size = os.path.getsize(onnx_path) / 1024 / 1024\n",
        "    \n",
        "    print(f\"\\n‚úÖ Modelos exportados:\")\n",
        "    print(f\"   PyTorch: {best_model_path} ({pt_size:.1f} MB)\")\n",
        "    print(f\"   ONNX:    {onnx_path} ({onnx_size:.1f} MB)\")\n",
        "    print(f\"\\nüí° El archivo ONNX funciona con ONNX Runtime en tu RTX 5080\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ el modelo entrenado. Ejecuta el entrenamiento primero.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8Ô∏è‚É£ PROBAR INFERENCIA CON EL MODELO\n",
        "# =====================================\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "best_model_path = f\"{WORK_DIR}/models/{PROYECTO}/weights/best.pt\"\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Buscar imagen de prueba\n",
        "    test_img = \"/content/coco128/images/train2017/000000000009.jpg\"\n",
        "    \n",
        "    if os.path.exists(test_img):\n",
        "        print(f\"üñºÔ∏è Probando inferencia...\")\n",
        "        \n",
        "        # Inferencia\n",
        "        results = model.predict(test_img, imgsz=IMG_SIZE, conf=0.25)\n",
        "        \n",
        "        # Mostrar resultado\n",
        "        result_img = results[0].plot()\n",
        "        result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(result_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Detecciones: {len(results[0].boxes)}')\n",
        "        plt.show()\n",
        "        \n",
        "        # Listar detecciones\n",
        "        print(f\"\\nüìã Objetos detectados: {len(results[0].boxes)}\")\n",
        "        for box in results[0].boxes:\n",
        "            cls = int(box.cls.item())\n",
        "            conf = box.conf.item()\n",
        "            name = model.names[cls]\n",
        "            print(f\"   - {name}: {conf:.2%}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Entrena el modelo primero\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9Ô∏è‚É£ DESCARGAR MODELO (alternativa a Google Drive)\n",
        "# ===================================================\n",
        "from google.colab import files\n",
        "\n",
        "best_model_path = f\"{WORK_DIR}/models/{PROYECTO}/weights/best.pt\"\n",
        "onnx_path = best_model_path.replace(\".pt\", \".onnx\")\n",
        "\n",
        "print(\"üì• Descargando modelos al PC...\")\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    files.download(best_model_path)\n",
        "    print(f\"   ‚úÖ {best_model_path}\")\n",
        "    \n",
        "if os.path.exists(onnx_path):\n",
        "    files.download(onnx_path)\n",
        "    print(f\"   ‚úÖ {onnx_path}\")\n",
        "\n",
        "print(\"\\nüí° Tambi√©n puedes copiar desde Google Drive: Sussy_Training/models/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Notas Importantes\n",
        "\n",
        "### Para tu propio dataset:\n",
        "\n",
        "1. **Detecci√≥n (Fase 1):** Sube im√°genes completas + archivos `.txt` con bounding boxes\n",
        "2. **Clasificaci√≥n (Fases 2-3):** Sube crops organizados en carpetas por clase\n",
        "\n",
        "### Formato de anotaci√≥n YOLO (archivo .txt):\n",
        "```\n",
        "# clase x_centro y_centro ancho alto (todo normalizado 0-1)\n",
        "0 0.5 0.5 0.2 0.3\n",
        "1 0.25 0.75 0.1 0.15\n",
        "```\n",
        "\n",
        "### Recomendaciones:\n",
        "- **Pruebas r√°pidas:** 30-50 epochs con yolo11n.pt\n",
        "- **Entrenamiento serio:** 100-300 epochs con yolo11m.pt o yolo11l.pt\n",
        "- **Si hay error de memoria:** Reduce BATCH_SIZE (16 ‚Üí 8 ‚Üí 4)\n",
        "\n",
        "### Pr√≥ximos pasos:\n",
        "1. ‚úÖ Probar este notebook con COCO128\n",
        "2. ‚¨ú Extraer frames de tus v√≠deos con `extraer_frames.py`\n",
        "3. ‚¨ú Anotar im√°genes (usa [Label Studio](https://labelstud.io/) o [CVAT](https://cvat.ai/))\n",
        "4. ‚¨ú Subir dataset a Google Drive\n",
        "5. ‚¨ú Entrenar con tu dataset\n",
        "6. ‚¨ú Exportar ONNX e integrar en Sistema Sussy\n",
        "\n",
        "---\n",
        "*Sistema Sussy - Entrenamiento Jer√°rquico v1.0*"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
